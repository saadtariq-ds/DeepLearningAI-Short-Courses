{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a92752e-3e54-4af4-bff2-13e8378ade30",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "373ef267-36f4-4fe4-8871-8e5fa428095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import wandb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Adam\n",
    "from utilities import get_dataloaders\n",
    "from pathlib import Path\n",
    "from types import SimpleNamespace\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cd4cba-4a30-4b5e-b86d-4c82080d9db5",
   "metadata": {},
   "source": [
    "## Sprite Classification\n",
    "\n",
    "We will build a simple model to classify sprites. You can see some examples of sprites and corresponding classes in the image below.\n",
    "\n",
    "<img src=\"images/sprite_sample.png\" alt=\"Alt Text\" width=\"700\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30e84e4a-7c43-420e-93fe-7ee608704fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = 3 * 16 * 16\n",
    "OUTPUT_SIZE = 5\n",
    "HIDDEN_SIZE = 256\n",
    "NUM_WORKERS = 2\n",
    "CLASSES = [\"hero\", \"non-hero\", \"food\", \"spell\", \"side-facing\"]\n",
    "DATA_DIR = Path('./data/')\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available()  else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58ca59a9-54f3-45d0-b384-94f632bca42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(dropout):\n",
    "    \"Simple MLP with Dropout\"\n",
    "    return nn.Sequential(\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(INPUT_SIZE, HIDDEN_SIZE),\n",
    "        nn.BatchNorm1d(HIDDEN_SIZE),\n",
    "        nn.ReLU(),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE)\n",
    "    ).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b998a291-6874-4e6e-8c38-19509478e201",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SimpleNamespace(\n",
    "    epochs = 2,\n",
    "    batch_size = 128,\n",
    "    lr = 1e-5,\n",
    "    dropout = 0.5,\n",
    "    slice_size = 10_000,\n",
    "    valid_pct = 0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "461457b9-7f14-4de4-8c5a-a4b2bef321ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(config):\n",
    "    \"Train a model with a given config\"\n",
    "    \n",
    "    wandb.init(\n",
    "        project=\"wnb_introduction\",\n",
    "        config=config,\n",
    "    )\n",
    "\n",
    "    # Get the data\n",
    "    train_dl, valid_dl = get_dataloaders(DATA_DIR, \n",
    "                                         config.batch_size, \n",
    "                                         config.slice_size, \n",
    "                                         config.valid_pct)\n",
    "    n_steps_per_epoch = math.ceil(len(train_dl.dataset) / config.batch_size)\n",
    "\n",
    "    # A simple MLP model\n",
    "    model = get_model(config.dropout)\n",
    "\n",
    "    # Make the loss and optimizer\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=config.lr)\n",
    "\n",
    "    example_ct = 0\n",
    "\n",
    "    for epoch in tqdm(range(config.epochs), total=config.epochs):\n",
    "        model.train()\n",
    "\n",
    "        for step, (images, labels) in enumerate(train_dl):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            outputs = model(images)\n",
    "            train_loss = loss_func(outputs, labels)\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            example_ct += len(images)\n",
    "            metrics = {\n",
    "                \"train/train_loss\": train_loss,\n",
    "                \"train/epoch\": epoch + 1,\n",
    "                \"train/example_ct\": example_ct\n",
    "            }\n",
    "            wandb.log(metrics)\n",
    "            \n",
    "        # Compute validation metrics, log images on last epoch\n",
    "        val_loss, accuracy = validate_model(model, valid_dl, loss_func)\n",
    "        # Compute train and validation metrics\n",
    "        val_metrics = {\n",
    "            \"val/val_loss\": val_loss,\n",
    "            \"val/val_accuracy\": accuracy\n",
    "        }\n",
    "        wandb.log(val_metrics)\n",
    "    \n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4db76e9-af69-4b4c-b894-802540d309c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, valid_dl, loss_func):\n",
    "    \"Compute the performance of the model on the validation dataset\"\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        for i, (images, labels) in enumerate(valid_dl):\n",
    "            images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(images)\n",
    "            val_loss += loss_func(outputs, labels) * labels.size(0)\n",
    "\n",
    "            # Compute accuracy and accumulate\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    return val_loss / len(valid_dl.dataset), correct / len(valid_dl.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e04be411-2dea-4146-8511-5ac05d31924b",
   "metadata": {},
   "source": [
    "## W&B Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82044fb3-e561-43c6-8d91-0a27398ce26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.login(anonymous=\"allow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ba02603-7e1d-4616-aa7d-cacba4e77a4d",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c85c434c-6976-40d1-98c7-d1cae016284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_model(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "91cc4779-b71e-4ba2-9149-9a96395087dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.lr = 1e-4\n",
    "# train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d7daf45-7211-447e-8c62-000a54c33dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config.dropout = 0.1\n",
    "# config.epochs = 1\n",
    "# train_model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32b08f7-a898-44d3-a484-4549148ebbc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
