{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "448fe8e6-1ced-4aa3-b89c-4fe5a084bf5a",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "522d4631-c611-4013-8adf-eca97932b8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "from tenacity import (\n",
    "    retry,\n",
    "    stop_after_attempt,\n",
    "    wait_random_exponential, # for exponential backoff\n",
    ")  \n",
    "import wandb\n",
    "from wandb.sdk.data_types.trace_tree import Trace\n",
    "\n",
    "from langchain.agents import AgentType, initialize_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.tools import BaseTool\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from langchain.callbacks.manager import (\n",
    "    AsyncCallbackManagerForToolRun,\n",
    "    CallbackManagerForToolRun,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff14cfa1-2be7-41d3-872f-7f1bcf18c25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) \n",
    "\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "291db4f2-a547-4017-87ad-189cfb610126",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9d4b236-afa5-45ec-9d93-c00a2c060b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c9de7c9-2d02-4a4d-baec-4d0715979d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = \"llm_evaluation\"\n",
    "MODEL_NAME = \"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc6d0457-c599-4586-b794-d4a59fcf4931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.login(anonymous=\"allow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f34d5047-9b5c-4aa4-a908-1c54759f40a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run = wandb.init(project=PROJECT, job_type=\"generation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc110677-c8b7-4064-90c8-97480c8dd7c1",
   "metadata": {},
   "source": [
    "## Simple Generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6138d8a2-3dcb-47b9-97fe-12e5ec407648",
   "metadata": {},
   "outputs": [],
   "source": [
    "@retry(wait=wait_random_exponential(min=1, max=60), stop=stop_after_attempt(6))\n",
    "def completion_with_backoff(**kwargs):\n",
    "    return client.chat.completions.create(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44270fe8-fdd6-40d2-b42a-40d813a1f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_print(system_prompt, user_prompt, table, n=5):\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": user_prompt},\n",
    "    ]\n",
    "    \n",
    "    start_time = time.time()\n",
    "    responses = completion_with_backoff(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "        n = n,\n",
    "    )\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    for response in responses.choices:\n",
    "        generation = response.message.content\n",
    "        print(generation)\n",
    "        \n",
    "    table.add_data(\n",
    "        system_prompt,\n",
    "        user_prompt,\n",
    "        [response.message.content for response in responses.choices],\n",
    "        elapsed_time,\n",
    "        datetime.datetime.fromtimestamp(responses.created),\n",
    "        responses.model,\n",
    "        responses.usage.prompt_tokens,\n",
    "        responses.usage.completion_tokens,\n",
    "        responses.usage.total_tokens\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f51e952a-3d68-4d5d-b4d5-6a24b9fdad3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are a creative copywriter.\n",
    "You're given a category of game asset, \\\n",
    "and your goal is to design a name of that asset.\n",
    "The game is set in a fantasy world \\\n",
    "where everyone laughs and respects each other, \n",
    "while celebrating diversity.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b19f8619-5566-4e99-b781-524a6dfd50c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define W&B Table to store generations\n",
    "columns = [\n",
    "    \"system_prompt\", \"user_prompt\", \"generations\", \"elapsed_time\", \"timestamp\",\n",
    "    \"model\", \"prompt_tokens\", \"completion_tokens\", \"total_tokens\"\n",
    "]\n",
    "\n",
    "table = wandb.Table(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b231003e-8a2b-415c-a287-e055288c1b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Harmony Champion\n",
      "Champion of Unity\n",
      "Champion of Harmony\n",
      "Champion of Harmony\n",
      "Unity Champion\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"hero\"\n",
    "generate_and_print(system_prompt, user_prompt, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10b5b482-6fd6-4453-a2eb-c0d6a869b2a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Joyful Gemstones\n",
      "Sparkling Harmony Gems\n",
      " Harmony Gemstones\n",
      "Whimsy Gemstones\n",
      "DazzleGleam Gems\n"
     ]
    }
   ],
   "source": [
    "user_prompt = \"jewel\"\n",
    "generate_and_print(system_prompt, user_prompt, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8dd470a1-ed55-46c8-9f60-74cffa05a8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.log({\"simple_generations\": table})\n",
    "# run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff15ecd-05f5-465e-a91c-3a7fcd87a6ef",
   "metadata": {},
   "source": [
    "## Using Tracer to log more complex chains\n",
    "\n",
    "Let's design an LLM chain that will first randomly pick a fantasy world, and then generate character names. We will demonstrate how to use Tracer in such scenario. We will log the inputs and outputs, start and end times, whether the OpenAI call was successful, the token usage, and additional metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf23faa1-48ab-4015-a5cb-58639d303d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "worlds = [\n",
    "    \"a mystic medieval island inhabited by intelligent and funny frogs\",\n",
    "    \"a modern castle sitting on top of a volcano in a faraway galaxy\",\n",
    "    \"a digital world inhabited by friendly machine learning engineers\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da8ac9d5-a45b-4746-9a36-ec0a239e809d",
   "metadata": {},
   "source": [
    "### Define your config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e57caad-f68a-40a7-b697-f795e489cb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt-3.5-turbo\"\n",
    "temperature = 0.7\n",
    "\n",
    "system_message = \"\"\"You are a creative copywriter. \n",
    "You're given a category of game asset and a fantasy world.\n",
    "Your goal is to design a name of that asset.\n",
    "Provide the resulting name only, no additional description.\n",
    "Single name, max 3 words output, remember!\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bdcceca6-6075-452a-b4f9-641feb8ae149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_creative_chain(query):\n",
    "    # part 1 - a chain is started...\n",
    "    start_time_ms = round(datetime.datetime.now().timestamp() * 1000)\n",
    "\n",
    "    root_span = Trace(\n",
    "          name=\"MyCreativeChain\",\n",
    "          kind=\"chain\",\n",
    "          start_time_ms=start_time_ms,\n",
    "          metadata={\"user\": \"student_1\"},\n",
    "          model_dict={\"_kind\": \"CreativeChain\"}\n",
    "          )\n",
    "\n",
    "    # part 2 - your chain picks a fantasy world\n",
    "    time.sleep(3)\n",
    "    world = random.choice(worlds)\n",
    "    expanded_prompt = f'Game asset category: {query}; fantasy world description: {world}'\n",
    "    tool_end_time_ms = round(datetime.datetime.now().timestamp() * 1000)\n",
    "\n",
    "    # create a Tool span \n",
    "    tool_span = Trace(\n",
    "          name=\"WorldPicker\",\n",
    "          kind=\"tool\",\n",
    "          status_code=\"success\",\n",
    "          start_time_ms=start_time_ms,\n",
    "          end_time_ms=tool_end_time_ms,\n",
    "          inputs={\"input\": query},\n",
    "          outputs={\"result\": expanded_prompt},\n",
    "          model_dict={\"_kind\": \"tool\", \"num_worlds\": len(worlds)}\n",
    "          )\n",
    "\n",
    "    # add the TOOL span as a child of the root\n",
    "    root_span.add_child(tool_span)\n",
    "\n",
    "    # part 3 - the LLMChain calls an OpenAI LLM...\n",
    "    messages=[\n",
    "      {\"role\": \"system\", \"content\": system_message},\n",
    "      {\"role\": \"user\", \"content\": expanded_prompt}\n",
    "    ]\n",
    "\n",
    "    responses = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=12\n",
    "    )\n",
    "\n",
    "    llm_end_time_ms = round(datetime.datetime.now().timestamp() * 1000)\n",
    "    \n",
    "    for response in responses.choices:\n",
    "        response_text = response.message.content\n",
    "        \n",
    "    token_usage = responses.usage.total_tokens\n",
    "\n",
    "    llm_span = Trace(\n",
    "          name=\"OpenAI\",\n",
    "          kind=\"llm\",\n",
    "          status_code=\"success\",\n",
    "          metadata={\"temperature\":temperature,\n",
    "                    \"token_usage\": token_usage, \n",
    "                    \"model_name\":model_name},\n",
    "          start_time_ms=tool_end_time_ms,\n",
    "          end_time_ms=llm_end_time_ms,\n",
    "          inputs={\"system_prompt\":system_message, \"query\":expanded_prompt},\n",
    "          outputs={\"response\": response_text},\n",
    "          model_dict={\"_kind\": \"Openai\", \"engine\": responses.model, \"model\": responses.object}\n",
    "          )\n",
    "\n",
    "    # add the LLM span as a child of the Chain span...\n",
    "    root_span.add_child(llm_span)\n",
    "\n",
    "    # update the end time of the Chain span\n",
    "    root_span.add_inputs_and_outputs(\n",
    "          inputs={\"query\":query},\n",
    "          outputs={\"response\": response_text})\n",
    "\n",
    "    # update the Chain span's end time\n",
    "    root_span.end_time_ms = llm_end_time_ms\n",
    "\n",
    "\n",
    "    # part 4 - log all spans to W&B by logging the root span\n",
    "    root_span.log(name=\"creative_trace\")\n",
    "    print(f\"Result: {response_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "06cc258f-ca5e-4ae0-91a7-ab59c0a7b660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=PROJECT, job_type=\"generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2e5d55c-cca9-4ec9-8974-f09d2289419d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Volcano Knight\n"
     ]
    }
   ],
   "source": [
    "run_creative_chain(\"hero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb4c0989-6447-48c2-a98d-6d0e8fa0c832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Volcanite Gem\n"
     ]
    }
   ],
   "source": [
    "run_creative_chain(\"jewel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dae63401-7321-4af8-b9ee-0e2887ab6a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca6d12c-3fff-47a3-b46f-68011502fad6",
   "metadata": {},
   "source": [
    "## Langchain Agent\n",
    "\n",
    "In the third scenario, we'll introduce an agent that will use tools such as WorldPicker and NameValidator to come up with the ultimate name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "559e0e75-2406-427b-918f-8d4242796608",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=PROJECT, job_type=\"generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "73cdd3c9-7942-48f5-94a8-ceedfd319512",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "defc0672-b0fd-4976-aed4-47ca01d16ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dad963e1-01d4-4d18-ba6e-fc3c16e63139",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WorldPickerTool(BaseTool):\n",
    "    name:str = \"pick_world\"\n",
    "    description:str = \"pick a virtual game world for your character or item naming\"\n",
    "    worlds:list[str] = [\n",
    "        \"a mystic medieval island inhabited by intelligent and funny frogs\",\n",
    "        \"a modern anthill featuring a cyber-ant queen and her cyber-ant-workers\",\n",
    "        \"a digital world inhabited by friendly machine learning engineers\"\n",
    "    ]\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        time.sleep(1)\n",
    "        return random.choice(self.worlds)\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"pick_world does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54f4ec7f-79e2-4a01-b761-d92cbb4e67b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NameValidatorTool(BaseTool):\n",
    "    name:str = \"validate_name\"\n",
    "    description:str = \"validate if the name is properly generated\"\n",
    "\n",
    "    def _run(\n",
    "        self, query: str, run_manager: Optional[CallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool.\"\"\"\n",
    "        time.sleep(1)\n",
    "        if len(query) < 20:\n",
    "            return f\"This is a correct name: {query}\"\n",
    "        else:\n",
    "            return f\"This name is too long. It should be shorter than 20 characters.\"\n",
    "\n",
    "    async def _arun(\n",
    "        self, query: str, run_manager: Optional[AsyncCallbackManagerForToolRun] = None\n",
    "    ) -> str:\n",
    "        \"\"\"Use the tool asynchronously.\"\"\"\n",
    "        raise NotImplementedError(\"validate_name does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b850966-f0d5-4460-a967-0c67cf491884",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [WorldPickerTool(), NameValidatorTool()]\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools, \n",
    "    llm, \n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    handle_parsing_errors=True,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff18c022-6feb-4953-b041-779b215ba368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> Entering new AgentExecutor chain...\n",
      "I need to pick a virtual game world first and then come up with a hero name within that world.\n",
      "Action: pick_world\n",
      "Action Input: Netherworld\n",
      "Observation: a digital world inhabited by friendly machine learning engineers\n",
      "Thought:Now I need to come up with a hero name within the Netherworld.\n",
      "Action: validate_name\n",
      "Action Input: Shadowstrike\n",
      "Observation: This is a correct name: Shadowstrike\n",
      "Thought:I now know the final answer\n",
      "Final Answer: The hero name in the virtual game world of Netherworld is Shadowstrike.\n",
      "\n",
      "> Finished chain.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Find a virtual game world for me and imagine the name of a hero in that world',\n",
       " 'output': 'The hero name in the virtual game world of Netherworld is Shadowstrike.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"Find a virtual game world for me and imagine the name of a hero in that world\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "546b9f8d-95f5-47de-a5e9-66232d5dd73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> Entering new AgentExecutor chain...\n",
      "I need to pick a virtual game world and come up with a food name for that world.\n",
      "Action: pick_world\n",
      "Action Input:\n",
      "Observation: a digital world inhabited by friendly machine learning engineers\n",
      "Thought:I need to come up with a food name that fits in a world inhabited by friendly machine learning engineers.\n",
      "Action: validate_name\n",
      "Action Input: Crunchy Circuits\n",
      "Observation: This is a correct name: Crunchy Circuits\n",
      "Thought:I now know the final answer\n",
      "Final Answer: The name of the food in the virtual game world is Crunchy Circuits.\n",
      "\n",
      "> Finished chain.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Find a virtual game world for me and imagine the name of food in that world.',\n",
       " 'output': 'The name of the food in the virtual game world is Crunchy Circuits.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.invoke(\n",
    "    \"Find a virtual game world for me and imagine the name of food in that world.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5e36ff1d-45e3-4f62-9f7e-46d26e301c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e5600f-0710-43cf-91b6-89bfdbfcc610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
