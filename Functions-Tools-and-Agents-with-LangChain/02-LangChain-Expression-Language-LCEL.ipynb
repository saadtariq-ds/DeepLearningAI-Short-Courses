{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd35d852-5e2d-45d7-9641-0c62db9fcfed",
   "metadata": {},
   "source": [
    "## Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e4d7495-8774-493c-8f60-45ccdf80190f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_openai.llms import OpenAI\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables.base import RunnableMap\n",
    "from langchain_community.vectorstores import DocArrayInMemorySearch\n",
    "from dotenv import load_dotenv, find_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "276bb244-620b-4a72-9392-8234c9f9295d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "117d8bc6-429b-48d1-94f3-c1c785ed0ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5f4b9b1-484a-419d-ac8a-a1d8ad816cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd58b18-326a-4175-9b1f-1eb824b5ce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6e34900-ef95-41ec-9a46-ca9a4e3cafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9397745b-d485-48a4-a842-73d8925033d3",
   "metadata": {},
   "source": [
    "## Simple Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2dadc2d8-5f35-4c63-b2d3-76fe7650644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"tell me a short joke about {topic}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6063a4be-9117-4165-b051-9dd4d5baf52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6c78def-760a-49d1-8c55-8692f67b7319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why did the dog sit in the shade? \\n\\nBecause he didn't want to be a hot dog!\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"dog\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5abb5d-dfc8-4687-92e9-4402a94e4994",
   "metadata": {},
   "source": [
    "## Complex Chain\n",
    "\n",
    "And Runnable Map to supply user-provided inputs to the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "07fd100a-3aaf-497e-832b-279255e7d04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = DocArrayInMemorySearch.from_texts(\n",
    "    texts=[\"harrison worked at kensho\", \"bears like to eat honey\"],\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "239e53a8-d195-410b-971a-7718cbdad780",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6e7d916-b45c-4045-bcc4-e0941ae5bdd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='harrison worked at kensho'),\n",
       " Document(metadata={}, page_content='bears like to eat honey')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"where did harrison work?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d248be56-c776-49ee-8a35-e89f61914f12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={}, page_content='bears like to eat honey'),\n",
       " Document(metadata={}, page_content='harrison worked at kensho')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.get_relevant_documents(\"what do bears like to eat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08df1648-e694-435e-945f-07d4be62a1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ff6f89e-b226-4963-ac9f-7e81204e5735",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = RunnableMap({\n",
    "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "554f2f72-ebbb-47e1-ba08-ebaee0b86738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Harrison worked at Kensho.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = runnable | prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4826eee-5f13-47c6-a6dc-512951f60fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': [Document(metadata={}, page_content='harrison worked at kensho'),\n",
       "  Document(metadata={}, page_content='bears like to eat honey')],\n",
       " 'question': 'where did harrison work?'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = runnable = RunnableMap({\n",
    "    \"context\": lambda x: retriever.get_relevant_documents(x[\"question\"]),\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "})\n",
    "\n",
    "inputs.invoke({\"question\": \"where did harrison work?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65d5e00-a579-4083-bcf1-e0623913aa2e",
   "metadata": {},
   "source": [
    "## Binding OpenAI Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59b04a35-b17f-4f57-9dde-a7ea3dd70146",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "      \"name\": \"weather_search\",\n",
    "      \"description\": \"Search for weather given an airport code\",\n",
    "      \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "          \"airport_code\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The airport code to get the weather for\"\n",
    "          },\n",
    "        },\n",
    "        \"required\": [\"airport_code\"]\n",
    "      }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38a1a9ce-5486-4fdd-8fc0-22f8f2f20131",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"human\", \"{input}\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c3ac777-f590-41bd-858f-576660a1ff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0).bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a7a3588-3b04-439c-a723-0e7f2d3fca95",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4aa5799d-31bb-4bfc-8045-1067320c01ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"airport_code\":\"SFO\"}', 'name': 'weather_search'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 64, 'total_tokens': 80, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BtU9pahXT68RBIlH9ycQw8I1ydURM', 'finish_reason': 'function_call', 'logprobs': None}, id='run--71a6d277-ae74-4a1b-861e-fbce308cd209-0', usage_metadata={'input_tokens': 64, 'output_tokens': 16, 'total_tokens': 80, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({\"input\": \"what is the weather in sf\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d6d6cba-a0c6-4121-9fde-cba2eb1c59e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"weather_search\",\n",
    "        \"description\": \"Search for weather given an airport code\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"airport_code\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The airport code to get the weather for\"\n",
    "                },\n",
    "            },\n",
    "        \"required\": [\"airport_code\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"sports_search\",\n",
    "        \"description\": \"Search for news of recent sport events\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"team_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The sports team to search for\"\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"team_name\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1ae1e45d-ba33-4c59-970b-bef3c98dd3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17a39d7e-2368-4109-a66a-488c5f99f24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "runnable = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c8867853-9e90-4dd9-b148-478f82453f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"team_name\":\"patriots\"}', 'name': 'sports_search'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 99, 'total_tokens': 117, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BtU9s7EKCHWncvNhoeemyozDCOOvJ', 'finish_reason': 'function_call', 'logprobs': None}, id='run--697be2ce-647b-477a-9c97-aa2686a89895-0', usage_metadata={'input_tokens': 99, 'output_tokens': 18, 'total_tokens': 117, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runnable.invoke({\"input\": \"how did the patriots do yesterday?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88746d3b-1476-403c-be75-54e93a31435a",
   "metadata": {},
   "source": [
    "## Fallbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ce9dbbde-6a1c-461a-b4b2-e366ceed5681",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = OpenAI(\n",
    "    temperature=0, \n",
    "    max_tokens=1000, \n",
    "    model=\"gpt-3.5-turbo-instruct\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33d35478-76bd-4a7b-9bf7-b89253939c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_chain = simple_model | json.loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cc327b0c-ef23-44bb-9b34-01227ef23430",
   "metadata": {},
   "outputs": [],
   "source": [
    "challenge = \"write three poems in a json blob, where each poem is a json blob of a title, author, and first line\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "652bd16c-18cc-490f-90a5-6c0a7fc03380",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n{\\n    \"title\": \"Autumn Leaves\",\\n    \"author\": \"Emily Dickinson\",\\n    \"first_line\": \"The leaves are falling, one by one\"\\n}\\n\\n{\\n    \"title\": \"The Ocean\\'s Song\",\\n    \"author\": \"Pablo Neruda\",\\n    \"first_line\": \"I hear the ocean\\'s song, a symphony of waves\"\\n}\\n\\n{\\n    \"title\": \"A Winter\\'s Night\",\\n    \"author\": \"Robert Frost\",\\n    \"first_line\": \"The snow falls softly, covering the ground\"\\n}'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_model.invoke(challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ac527f-f22e-4dc3-86da-e948ca1650e2",
   "metadata": {},
   "source": [
    "### Note: The next line is expected to fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "94f67ade-9bbc-431f-a6ce-82286996ef78",
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Extra data: line 9 column 1 (char 125)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43msimple_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchallenge\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Functions-Tools-and-Agents-with-LangChain-Env\\lib\\site-packages\\langchain_core\\runnables\\base.py:3047\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3045\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, input_, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3046\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3047\u001b[0m                 input_ \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3048\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[0;32m   3049\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Functions-Tools-and-Agents-with-LangChain-Env\\lib\\site-packages\\langchain_core\\runnables\\base.py:4772\u001b[0m, in \u001b[0;36mRunnableLambda.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   4758\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Invoke this Runnable synchronously.\u001b[39;00m\n\u001b[0;32m   4759\u001b[0m \n\u001b[0;32m   4760\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4769\u001b[0m \u001b[38;5;124;03m    TypeError: If the Runnable is a coroutine function.\u001b[39;00m\n\u001b[0;32m   4770\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4771\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunc\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 4772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_with_config(\n\u001b[0;32m   4773\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_invoke,\n\u001b[0;32m   4774\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   4775\u001b[0m         ensure_config(config),\n\u001b[0;32m   4776\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4777\u001b[0m     )\n\u001b[0;32m   4778\u001b[0m msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot invoke a coroutine function synchronously.Use `ainvoke` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4779\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Functions-Tools-and-Agents-with-LangChain-Env\\lib\\site-packages\\langchain_core\\runnables\\base.py:1940\u001b[0m, in \u001b[0;36mRunnable._call_with_config\u001b[1;34m(self, func, input_, config, run_type, serialized, **kwargs)\u001b[0m\n\u001b[0;32m   1936\u001b[0m     child_config \u001b[38;5;241m=\u001b[39m patch_config(config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child())\n\u001b[0;32m   1937\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(child_config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m   1938\u001b[0m         output \u001b[38;5;241m=\u001b[39m cast(\n\u001b[0;32m   1939\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m-> 1940\u001b[0m             context\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m   1941\u001b[0m                 call_func_with_variable_args,  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m   1942\u001b[0m                 func,\n\u001b[0;32m   1943\u001b[0m                 input_,\n\u001b[0;32m   1944\u001b[0m                 config,\n\u001b[0;32m   1945\u001b[0m                 run_manager,\n\u001b[0;32m   1946\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   1947\u001b[0m             ),\n\u001b[0;32m   1948\u001b[0m         )\n\u001b[0;32m   1949\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1950\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Functions-Tools-and-Agents-with-LangChain-Env\\lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    427\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Functions-Tools-and-Agents-with-LangChain-Env\\lib\\site-packages\\langchain_core\\runnables\\base.py:4630\u001b[0m, in \u001b[0;36mRunnableLambda._invoke\u001b[1;34m(self, input_, run_manager, config, **kwargs)\u001b[0m\n\u001b[0;32m   4628\u001b[0m                 output \u001b[38;5;241m=\u001b[39m chunk\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4630\u001b[0m     output \u001b[38;5;241m=\u001b[39m call_func_with_variable_args(\n\u001b[0;32m   4631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, input_, config, run_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   4632\u001b[0m     )\n\u001b[0;32m   4633\u001b[0m \u001b[38;5;66;03m# If the output is a Runnable, invoke it\u001b[39;00m\n\u001b[0;32m   4634\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, Runnable):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Functions-Tools-and-Agents-with-LangChain-Env\\lib\\site-packages\\langchain_core\\runnables\\config.py:428\u001b[0m, in \u001b[0;36mcall_func_with_variable_args\u001b[1;34m(func, input, config, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m accepts_run_manager(func):\n\u001b[0;32m    427\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m run_manager\n\u001b[1;32m--> 428\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Functions-Tools-and-Agents-with-LangChain-Env\\lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\Functions-Tools-and-Agents-with-LangChain-Env\\lib\\json\\decoder.py:340\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n\u001b[1;32m--> 340\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtra data\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, end)\n\u001b[0;32m    341\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Extra data: line 9 column 1 (char 125)"
     ]
    }
   ],
   "source": [
    "simple_chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "466f09e9-a066-4cd8-9963-aef47632b03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0)\n",
    "chain = model | StrOutputParser() | json.loads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6216fbfd-9a5b-4fd6-a613-2c555120441e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poem1': {'title': 'The Rose',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'A rose by any other name would smell as sweet'},\n",
       " 'poem2': {'title': 'The Road Not Taken',\n",
       "  'author': 'Robert Frost',\n",
       "  'firstLine': 'Two roads diverged in a yellow wood'},\n",
       " 'poem3': {'title': 'Hope is the Thing with Feathers',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'Hope is the thing with feathers that perches in the soul'}}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94e894f2-7cfe-4002-a065-5c882d6bd56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'poem1': {'title': 'The Rose',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'A rose by any other name would smell as sweet'},\n",
       " 'poem2': {'title': 'The Road Not Taken',\n",
       "  'author': 'Robert Frost',\n",
       "  'firstLine': 'Two roads diverged in a yellow wood'},\n",
       " 'poem3': {'title': 'Hope is the Thing with Feathers',\n",
       "  'author': 'Emily Dickinson',\n",
       "  'firstLine': 'Hope is the thing with feathers that perches in the soul'}}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain = simple_chain.with_fallbacks([chain])\n",
    "\n",
    "final_chain.invoke(challenge)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be24c751-46f3-4dfd-bbea-67529570fdb1",
   "metadata": {},
   "source": [
    "## Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "642ff8dd-6a8b-4432-b7ee-f3cda34d3cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\n",
    "    \"Tell me a short joke about {topic}\"\n",
    ")\n",
    "\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4af60f7d-9d79-40f7-93d2-ffc143bbb184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why do dogs run in circles before lying down? Because it's too hard to make a square!\""
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"topic\": \"dogs\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f4b86c1a-964d-4281-810a-84f1ed324b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Why don't dogs make good dancers? \\n\\nBecause they have two left feet!\",\n",
       " 'Why did the frog take the bus to work? Because his car got toad away!']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.batch([{\"topic\": \"dogs\"}, {\"topic\": \"frogs\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eeb9d148-5c75-4e65-9d27-5316cfbf107e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Why\n",
      " do\n",
      " dogs\n",
      " run\n",
      " in\n",
      " circles\n",
      " before\n",
      " lying\n",
      " down\n",
      "?\n",
      " \n",
      "\n",
      "\n",
      "Because\n",
      " it\n",
      "'s\n",
      " too\n",
      " hard\n",
      " to\n",
      " make\n",
      " a\n",
      " square\n",
      " bed\n",
      " with\n",
      " round\n",
      " p\n",
      "aws\n",
      "!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in chain.stream({\"topic\": \"dogs\"}):\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd5d6414-a92a-4a0b-ab78-b145bb4bcf6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why do dogs run in circles before lying down? \\nBecause they\\'re trying to make a \"ruff\" impression!'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await chain.ainvoke({\"topic\": \"dogs\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67dd7b7a-33a9-4a57-baaa-18a2ff7338bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
