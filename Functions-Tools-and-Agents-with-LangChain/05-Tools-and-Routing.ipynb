{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37aa4e58-3ddf-4412-93b3-695d05bb6669",
   "metadata": {},
   "source": [
    "## Setup and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a502b589-aa18-4cdf-a0db-ae40845dcff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import datetime\n",
    "import wikipedia\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.openai_functions.openapi import openapi_spec_to_openai_fn\n",
    "from langchain.utilities.openapi import OpenAPISpec\n",
    "from langchain_core.utils.function_calling import format_tool_to_openai_function\n",
    "from langchain_core.agents import AgentFinish\n",
    "from langchain.agents.output_parsers.openai_functions import OpenAIFunctionsAgentOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffc8d55c-09f9-44f0-ad3d-40ae74380297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4b83c0b-3430-4b2f-a20f-026d68797294",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cca32b52-3b24-432b-b274-5e5ba461d68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109d9c53-dc0a-4638-9bb2-2e73ec7bfe0e",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dae96c1c-f1e1-466c-abb0-6fc0f5ffbd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for weather online\"\"\"\n",
    "    return \"42f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f2b67780-b338-4209-9de0-fe14a75be30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Name: search\n",
      "Tool Description: Search for weather online\n",
      "Tool Args: {'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tool Name: {search.name}\")\n",
    "print(f\"Tool Description: {search.description}\")\n",
    "print(f\"Tool Args: {search.args}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "604746ed-4275-425e-ad84-5d6ecf745882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SearchInput(BaseModel):\n",
    "    query: str = Field(description=\"Thing to search for\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4dc28ca5-006a-466f-9d68-fdf46489704c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool(args_schema=SearchInput)\n",
    "def search(query: str) -> str:\n",
    "    \"\"\"Search for the weather online.\"\"\"\n",
    "    return \"42f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4974d22-0c05-45d9-b178-63411bf0a1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool Name: search\n",
      "Tool Description: Search for the weather online.\n",
      "Tool Args: {'query': {'description': 'Thing to search for', 'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Tool Name: {search.name}\")\n",
    "print(f\"Tool Description: {search.description}\")\n",
    "print(f\"Tool Args: {search.args}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1b6e2ea-c5fa-4420-875e-704e3aba6a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'42f'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search.run(\"sf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c28d0c62-2090-43b7-bff4-20aaff4828a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OpenMeteoInput(BaseModel):\n",
    "    latitude: float = Field(..., description=\"Latitude of the location to fetch weather data for\")\n",
    "    longitude: float = Field(..., description=\"Longitude of the location to fetch weather data for\")\n",
    "\n",
    "\n",
    "@tool(args_schema=OpenMeteoInput)\n",
    "def get_current_temperature(latitude: float, longitude: float) -> dict:\n",
    "    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n",
    "    \n",
    "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
    "    \n",
    "    # Parameters for the request\n",
    "    params = {\n",
    "        'latitude': latitude,\n",
    "        'longitude': longitude,\n",
    "        'hourly': 'temperature_2m',\n",
    "        'forecast_days': 1,\n",
    "    }\n",
    "\n",
    "    # Make the request\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        results = response.json()\n",
    "    else:\n",
    "        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n",
    "\n",
    "    current_utc_time = datetime.datetime.utcnow()\n",
    "    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]\n",
    "    temperature_list = results['hourly']['temperature_2m']\n",
    "    \n",
    "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n",
    "    current_temperature = temperature_list[closest_time_index]\n",
    "    \n",
    "    return f'The current temperature is {current_temperature}°C'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "76d5534f-3d21-4abb-83f2-ba02fedb47a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temperature Tool Name: get_current_temperature\n",
      "Temperature Description: Fetch current temperature for given coordinates.\n",
      "Temperature Args: {'latitude': {'description': 'Latitude of the location to fetch weather data for', 'title': 'Latitude', 'type': 'number'}, 'longitude': {'description': 'Longitude of the location to fetch weather data for', 'title': 'Longitude', 'type': 'number'}}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Temperature Tool Name: {get_current_temperature.name}\")\n",
    "print(f\"Temperature Description: {get_current_temperature.description}\")\n",
    "print(f\"Temperature Args: {get_current_temperature.args}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0a1084-fab5-4bf2-9d96-2424edc24b31",
   "metadata": {},
   "source": [
    "### Converting Tools to OpenAI Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eb1f912-625e-4242-a6fc-238206313ec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'get_current_temperature',\n",
       " 'description': 'Fetch current temperature for given coordinates.',\n",
       " 'parameters': {'properties': {'latitude': {'description': 'Latitude of the location to fetch weather data for',\n",
       "    'type': 'number'},\n",
       "   'longitude': {'description': 'Longitude of the location to fetch weather data for',\n",
       "    'type': 'number'}},\n",
       "  'required': ['latitude', 'longitude'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_tool_to_openai_function(get_current_temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dfe6331-ed15-4960-9d50-6c57c731422f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature is 25.5°C'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature({\"latitude\": 13, \"longitude\": 14})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1175d859-a569-4835-bfea-55bc82c1bfd2",
   "metadata": {},
   "source": [
    "### Wikipedia Tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e473a1fa-b255-4228-b17b-5e07af59c8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def search_wikipedia(query: str) -> str:\n",
    "    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n",
    "    page_titles = wikipedia.search(query)\n",
    "    summaries = []\n",
    "    for page_title in page_titles[: 3]:\n",
    "        try:\n",
    "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)\n",
    "            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n",
    "        except (\n",
    "            self.wiki_client.exceptions.PageError,\n",
    "            self.wiki_client.exceptions.DisambiguationError,\n",
    "        ):\n",
    "            pass\n",
    "    if not summaries:\n",
    "        return \"No good Wikipedia Search Result was found\"\n",
    "    return \"\\n\\n\".join(summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58b205e4-ec68-49b7-aa22-04cb2996125e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia Tool Name: search_wikipedia\n",
      "Wikipedia Description: Run Wikipedia search and get page summaries.\n",
      "Wikipedia Args: {'query': {'title': 'Query', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Wikipedia Tool Name: {search_wikipedia.name}\")\n",
    "print(f\"Wikipedia Description: {search_wikipedia.description}\")\n",
    "print(f\"Wikipedia Args: {search_wikipedia.args}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3c237f7-e986-4f16-bd09-56636fdc67ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'search_wikipedia',\n",
       " 'description': 'Run Wikipedia search and get page summaries.',\n",
       " 'parameters': {'properties': {'query': {'type': 'string'}},\n",
       "  'required': ['query'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_tool_to_openai_function(search_wikipedia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0a057430-d9b5-4772-97cb-f3c0960b4a5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Model Context Protocol\\nSummary: The Model Context Protocol (MCP) is an open standard, open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) systems like large language models (LLMs) integrate and share data with external tools, systems, and data sources. MCP provides a universal interface for reading files, executing functions, and handling contextual prompts. Following its announcement, the protocol was adopted by major AI providers, including OpenAI and Google DeepMind.\\n\\nPage: Retrieval-augmented generation\\nSummary: Retrieval-augmented generation (RAG) is a technique that enables large language models (LLMs) to retrieve and incorporate new information. With RAG, LLMs do not respond to user queries until they refer to a specified set of documents. These documents supplement information from the LLM\\'s pre-existing training data. This allows LLMs to use domain-specific and/or updated information that is not available in the training data. For example, this helps LLM-based chatbots access internal company data or generate responses based on authoritative sources.\\nRAG improves large language models (LLMs) by incorporating information retrieval before generating responses. Unlike traditional LLMs that rely on static training data, RAG pulls relevant text from databases, uploaded documents, or web sources. According to Ars Technica, \"RAG is a way of improving LLM performance, in essence by blending the LLM process with a web search or other document look-up process to help LLMs stick to the facts.\" This method helps reduce AI hallucinations, which have caused chatbots to describe policies that don\\'t exist, or recommend nonexistent legal cases to lawyers that are looking for citations to support their arguments.\\nRAG also reduces the need to retrain LLMs with new data, saving on computational and financial costs. Beyond efficiency gains, RAG also allows LLMs to include sources in their responses, so users can verify the cited sources. This provides greater transparency, as users can cross-check retrieved content to ensure accuracy and relevance.\\nThe term RAG was first introduced in a 2020 research paper from Meta.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_wikipedia({\"query\": \"langchain\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eba3337-71df-4a63-8f54-d5c29b66bfe8",
   "metadata": {},
   "source": [
    "### OpenAPI Specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bba5cd0b-57f6-4ba1-8e4c-f9593bd908b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "{\n",
    "  \"openapi\": \"3.0.0\",\n",
    "  \"info\": {\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"title\": \"Swagger Petstore\",\n",
    "    \"license\": {\n",
    "      \"name\": \"MIT\"\n",
    "    }\n",
    "  },\n",
    "  \"servers\": [\n",
    "    {\n",
    "      \"url\": \"http://petstore.swagger.io/v1\"\n",
    "    }\n",
    "  ],\n",
    "  \"paths\": {\n",
    "    \"/pets\": {\n",
    "      \"get\": {\n",
    "        \"summary\": \"List all pets\",\n",
    "        \"operationId\": \"listPets\",\n",
    "        \"tags\": [\n",
    "          \"pets\"\n",
    "        ],\n",
    "        \"parameters\": [\n",
    "          {\n",
    "            \"name\": \"limit\",\n",
    "            \"in\": \"query\",\n",
    "            \"description\": \"How many items to return at one time (max 100)\",\n",
    "            \"required\": false,\n",
    "            \"schema\": {\n",
    "              \"type\": \"integer\",\n",
    "              \"maximum\": 100,\n",
    "              \"format\": \"int32\"\n",
    "            }\n",
    "          }\n",
    "        ],\n",
    "        \"responses\": {\n",
    "          \"200\": {\n",
    "            \"description\": \"A paged array of pets\",\n",
    "            \"headers\": {\n",
    "              \"x-next\": {\n",
    "                \"description\": \"A link to the next page of responses\",\n",
    "                \"schema\": {\n",
    "                  \"type\": \"string\"\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Pets\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          },\n",
    "          \"default\": {\n",
    "            \"description\": \"unexpected error\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Error\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"post\": {\n",
    "        \"summary\": \"Create a pet\",\n",
    "        \"operationId\": \"createPets\",\n",
    "        \"tags\": [\n",
    "          \"pets\"\n",
    "        ],\n",
    "        \"responses\": {\n",
    "          \"201\": {\n",
    "            \"description\": \"Null response\"\n",
    "          },\n",
    "          \"default\": {\n",
    "            \"description\": \"unexpected error\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Error\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    },\n",
    "    \"/pets/{petId}\": {\n",
    "      \"get\": {\n",
    "        \"summary\": \"Info for a specific pet\",\n",
    "        \"operationId\": \"showPetById\",\n",
    "        \"tags\": [\n",
    "          \"pets\"\n",
    "        ],\n",
    "        \"parameters\": [\n",
    "          {\n",
    "            \"name\": \"petId\",\n",
    "            \"in\": \"path\",\n",
    "            \"required\": true,\n",
    "            \"description\": \"The id of the pet to retrieve\",\n",
    "            \"schema\": {\n",
    "              \"type\": \"string\"\n",
    "            }\n",
    "          }\n",
    "        ],\n",
    "        \"responses\": {\n",
    "          \"200\": {\n",
    "            \"description\": \"Expected response to a valid request\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Pet\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          },\n",
    "          \"default\": {\n",
    "            \"description\": \"unexpected error\",\n",
    "            \"content\": {\n",
    "              \"application/json\": {\n",
    "                \"schema\": {\n",
    "                  \"$ref\": \"#/components/schemas/Error\"\n",
    "                }\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  },\n",
    "  \"components\": {\n",
    "    \"schemas\": {\n",
    "      \"Pet\": {\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\n",
    "          \"id\",\n",
    "          \"name\"\n",
    "        ],\n",
    "        \"properties\": {\n",
    "          \"id\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"format\": \"int64\"\n",
    "          },\n",
    "          \"name\": {\n",
    "            \"type\": \"string\"\n",
    "          },\n",
    "          \"tag\": {\n",
    "            \"type\": \"string\"\n",
    "          }\n",
    "        }\n",
    "      },\n",
    "      \"Pets\": {\n",
    "        \"type\": \"array\",\n",
    "        \"maxItems\": 100,\n",
    "        \"items\": {\n",
    "          \"$ref\": \"#/components/schemas/Pet\"\n",
    "        }\n",
    "      },\n",
    "      \"Error\": {\n",
    "        \"type\": \"object\",\n",
    "        \"required\": [\n",
    "          \"code\",\n",
    "          \"message\"\n",
    "        ],\n",
    "        \"properties\": {\n",
    "          \"code\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"format\": \"int32\"\n",
    "          },\n",
    "          \"message\": {\n",
    "            \"type\": \"string\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8403f694-7784-4415-ad28-126a846a353e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Attempting to load an OpenAPI 3.0.0 spec.  This may result in degraded performance. Convert your OpenAPI spec to 3.1.* spec for better support.\n"
     ]
    }
   ],
   "source": [
    "spec = OpenAPISpec.from_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63764150-e1fa-4ffb-b6ae-203c01320291",
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_openai_functions, pet_callables = openapi_spec_to_openai_fn(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0140fa92-d765-4280-badc-834db5b9adee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'listPets',\n",
       "  'description': 'List all pets',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'params': {'type': 'object',\n",
       "     'properties': {'limit': {'type': 'integer',\n",
       "       'maximum': 100.0,\n",
       "       'schema_format': 'int32',\n",
       "       'description': 'How many items to return at one time (max 100)'}},\n",
       "     'required': []}}}},\n",
       " {'name': 'createPets',\n",
       "  'description': 'Create a pet',\n",
       "  'parameters': {'type': 'object', 'properties': {}}},\n",
       " {'name': 'showPetById',\n",
       "  'description': 'Info for a specific pet',\n",
       "  'parameters': {'type': 'object',\n",
       "   'properties': {'path_params': {'type': 'object',\n",
       "     'properties': {'petId': {'type': 'string',\n",
       "       'description': 'The id of the pet to retrieve'}},\n",
       "     'required': ['petId']}}}}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pet_openai_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "855725ee-e3ee-4757-beef-de7a93c11cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "bind_model = model.bind(functions=pet_openai_functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e26a1dc-2e1c-47a7-97d9-ee3499a5e9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"params\":{\"limit\":3}}', 'name': 'listPets'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 123, 'total_tokens': 139, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BuDB7X40q3L2ui0WGxpVN0VAD7Chm', 'finish_reason': 'function_call', 'logprobs': None}, id='run--be71c3f7-7269-4bc8-a13b-107508dfe1b5-0', usage_metadata={'input_tokens': 123, 'output_tokens': 16, 'total_tokens': 139, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bind_model.invoke(\"what are three pets names\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c1e3510a-bb5c-431f-986c-bc33826e8483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"path_params\":{\"petId\":\"42\"}}', 'name': 'showPetById'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 19, 'prompt_tokens': 126, 'total_tokens': 145, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BuDB8twSjUzSR4xrE65VtTLV7n2SV', 'finish_reason': 'function_call', 'logprobs': None}, id='run--96d8c8d3-672f-494c-94c8-ce440d82bc32-0', usage_metadata={'input_tokens': 126, 'output_tokens': 19, 'total_tokens': 145, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bind_model.invoke(\"tell me about pet with id 42\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e8e828-b218-4599-995a-73680b87ea9e",
   "metadata": {},
   "source": [
    "## Routing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "69514f6a-99b6-40ce-b40d-00986db48097",
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    format_tool_to_openai_function(f) for f in [\n",
    "        search_wikipedia, get_current_temperature\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6a6557d6-6ff4-45e1-b970-a26fe02888b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(temperature=0).bind(functions=functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9b918cd0-7f2d-4bc2-a163-3552b1073735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 105, 'total_tokens': 130, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BuDBFoYesWsIuhnclc7zq7Cchwd2a', 'finish_reason': 'function_call', 'logprobs': None}, id='run--b02809cd-4bdb-45c4-9f55-69ba21e307c8-0', usage_metadata={'input_tokens': 105, 'output_tokens': 25, 'total_tokens': 130, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is the weather in sf right now\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8825600-310b-4704-a7c6-14e13c6f55a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"query\":\"Langchain\"}', 'name': 'search_wikipedia'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 101, 'total_tokens': 117, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BuDBHtjug5bOom8rSBnuq4KwOaTbh', 'finish_reason': 'function_call', 'logprobs': None}, id='run--5f231ead-bc55-4016-96d9-0055a69b7c7b-0', usage_metadata={'input_tokens': 101, 'output_tokens': 16, 'total_tokens': 117, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "07698bf9-c6ac-4c62-bbbd-b53f99fb8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are helpful but sassy assistant\"),\n",
    "    (\"user\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8b442a3-93a8-4278-8313-c62af2055b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e89dc87-9c12-403a-b417-54d87b3f66a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'function_call': {'arguments': '{\"latitude\":37.7749,\"longitude\":-122.4194}', 'name': 'get_current_temperature'}, 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 113, 'total_tokens': 138, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'id': 'chatcmpl-BuDBV26iMAPnVjeqq3Mxrh4tyVwN6', 'finish_reason': 'function_call', 'logprobs': None}, id='run--dddab2fb-4048-4555-884d-e7361cd0e481-0', usage_metadata={'input_tokens': 113, 'output_tokens': 25, 'total_tokens': 138, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\": \"what is the weather in sf right now\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "114c9d7f-99f4-4da1-b2a9-6bd0f683951e",
   "metadata": {},
   "source": [
    "### Applying OpenAIFunctionsAgentOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8069ad94-0226-490c-9e8b-3d1633bbed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1ed0589-15c5-4520-a32c-a63f3a63f8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input\": \"what is the weather in sf right now\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b67d690-3f27-449d-ade8-83e13960daf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.agents.AgentActionMessageLog"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b78ac3ea-0293-4b59-b363-efad738d1f0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get_current_temperature'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8023354-d1e6-4aa4-b741-d34445facecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'latitude': 37.7749, 'longitude': -122.4194}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.tool_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dfbbcdf0-7876-475f-b4c0-94186167e8ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature is 14.1°C'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_temperature(response.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a656b1b-f096-4fb6-b405-7111298fde8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\"input\": \"hi!\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93a5b873-1d66-4403-924c-9f049363cf12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_core.agents.AgentFinish"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2cfbdfce-f2f0-4bff-a9a5-3fc38a11f5f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': 'Well, hello there! How can I assist you today?'}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.return_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8e6907-7aee-4118-89c5-c6f559a75d58",
   "metadata": {},
   "source": [
    "### Agent Finish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2de9ac0-4084-427e-9ae2-8ffc393ca016",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(result):\n",
    "    if isinstance(result, AgentFinish):\n",
    "        return result.return_values['output']\n",
    "    else:\n",
    "        tools = {\n",
    "            \"search_wikipedia\": search_wikipedia, \n",
    "            \"get_current_temperature\": get_current_temperature,\n",
    "        }\n",
    "        return tools[result.tool].run(result.tool_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "150521ba-2125-49c8-93ab-9fe5721b95a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | model | OpenAIFunctionsAgentOutputParser() | route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a58d197-698f-402e-a354-fba301059018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The current temperature is 14.1°C'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": \"What is the weather in san francisco right now?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3f2e4847-5b24-4c41-9754-dd0eb188eb40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Page: LangChain\\nSummary: LangChain is a software framework that helps facilitate the integration of large language models (LLMs) into applications. As a language model integration framework, LangChain\\'s use-cases largely overlap with those of language models in general, including document analysis and summarization, chatbots, and code analysis.\\n\\n\\n\\nPage: Model Context Protocol\\nSummary: The Model Context Protocol (MCP) is an open standard, open-source framework introduced by Anthropic in November 2024 to standardize the way artificial intelligence (AI) systems like large language models (LLMs) integrate and share data with external tools, systems, and data sources. MCP provides a universal interface for reading files, executing functions, and handling contextual prompts. Following its announcement, the protocol was adopted by major AI providers, including OpenAI and Google DeepMind.\\n\\nPage: Retrieval-augmented generation\\nSummary: Retrieval-augmented generation (RAG) is a technique that enables large language models (LLMs) to retrieve and incorporate new information. With RAG, LLMs do not respond to user queries until they refer to a specified set of documents. These documents supplement information from the LLM\\'s pre-existing training data. This allows LLMs to use domain-specific and/or updated information that is not available in the training data. For example, this helps LLM-based chatbots access internal company data or generate responses based on authoritative sources.\\nRAG improves large language models (LLMs) by incorporating information retrieval before generating responses. Unlike traditional LLMs that rely on static training data, RAG pulls relevant text from databases, uploaded documents, or web sources. According to Ars Technica, \"RAG is a way of improving LLM performance, in essence by blending the LLM process with a web search or other document look-up process to help LLMs stick to the facts.\" This method helps reduce AI hallucinations, which have caused chatbots to describe policies that don\\'t exist, or recommend nonexistent legal cases to lawyers that are looking for citations to support their arguments.\\nRAG also reduces the need to retrain LLMs with new data, saving on computational and financial costs. Beyond efficiency gains, RAG also allows LLMs to include sources in their responses, so users can verify the cited sources. This provides greater transparency, as users can cross-check retrieved content to ensure accuracy and relevance.\\nThe term RAG was first introduced in a 2020 research paper from Meta.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": \"What is langchain?\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "88f51222-d7d1-4c0b-926e-f84cfe47def3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well, hello there! How can I assist you today?'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"input\": \"hi!\"})\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4179cd57-4a88-41ce-afcb-1de5c74c9928",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
